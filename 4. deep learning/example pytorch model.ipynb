{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your ultimate task for this week is to build your first neural network [almost] from scratch and pure PyTorch.\n",
    "\n",
    "This time you will solve the same digit recognition problem, but at a larger scale\n",
    "\n",
    "* 10 different letters\n",
    "* 20k samples\n",
    "\n",
    "We want you to build a network that reaches at least 80% accuracy and has at least 2 linear layers in it. Naturally, it should be nonlinear to beat logistic regression.\n",
    "\n",
    "With 10 classes you will need to use __Softmax__ at the top instead of sigmoid and train using __categorical crossentropy__  (see [here](http://wiki.fast.ai/index.php/Log_Loss)).  Write your own loss or use `torch.nn.functional.nll_loss`. Just make sure you understand what it accepts as input.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from notmnist import load_notmnist\n",
    "# X_train, y_train, X_test, y_test = load_notmnist(letters='ABCDEFGHIJ')\n",
    "# X_train, X_test = X_train.reshape([-1, 784]), X_test.reshape([-1, 784])\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# create a dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "# create a data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# create a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 100), # 28*28 pixel iamges = 784 pixels per image in, 100 features out\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10), # 100 features in, 10 classes out\n",
    "    nn.LogSoftmax(dim=1) # log probabilities for each of the 10 classes\n",
    ")\n",
    "\n",
    "# create an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "# create a loss function\n",
    "loss_fn = nn.NLLLoss() # negative log likelihood loss\n",
    "\n",
    "# train the model\n",
    "for epoch in range(10):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        # compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "for X_batch, y_batch in test_loader:\n",
    "    y_pred = model(X_batch)\n",
    "    _, predicted = torch.max(y_pred.data, 1)\n",
    "    total += y_batch.size(0)\n",
    "    correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print('Accuracy: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "613f14d44ed673d1c984415509a5c5c52ed59778a2b3a835acb0571d1bad5d1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
